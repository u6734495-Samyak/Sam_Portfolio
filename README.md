# [Project 1: Potential useful Mg-Alloy : Project Overview](https://github.com/u6734495-Samyak/Comp4560)

A combination of lightweight, high specific strength, and good castability make magnesium alloys a promising engineering material for the automotive and aerospace industries. Vehicle weight reduction is one of the major means available to improve automotive fuel efficiency. High-strength steels, Aluminium (Al), and polymers are already being used to reduce weight significantly, but substantial additional reductions could be achieved by greater use of low-density magnesium (Mg) and its alloys. This project herein, therefore, relies on the use of machine learning, to assist in the development of A.I. to predict alloy compositions that are potentially useful for future metallic alloys. This study shows how a machine learning approach is able to offer acceptable precision predictions with respect to the main mechanical properties of metals.

![](/images/Pie.png)


# [Project 2: Breast Cancer Classifier : Project Overview](https://github.com/u6734495-Samyak/KaggleBreastCancer)

Using the Breast Cancer Wisconsin (Diagnostic) Database, we can create a classifier that can help diagnose patients and predict the likelihood of a breast cancer. A few machine learning techniques will be explored. 
* A few known machine learning classifiers were comapared against each other to obtain the best classifier.
* GridSearchCV was implemented that helped us obtain the best setting paramters for the desire classifier.
* In this particular exercise, Support Vector Machine was able to acheive the highest average and overall accuracy.

![](/images/metrics.png)


# [Project 3: A Simple Computer Vision Project : Project Overview](https://github.com/u6734495-Samyak/Computer-Vision)

* Basic Image I/O operations performed
* Equilization Task, Histogram , Histogram Equlization , R-G-B Equlization
* Image Denoising , Gaussian Filter , Sobel Filter
* Image rotation, Forward and backward Mapping.
  

![](images/gaussianoutput_3.jpg) 



# [Project 4:  Harris Corner Detection and K-means : Project Overview](https://github.com/u6734495-Samyak/Harris-Corner-and-Kmeans)

* Implemented Harris Corner Algorithm
* Non- Maximum Supression to detect only relevant corners
* K-Means ALgorithm
* K means ++


![](/images/Corner_4.jpg)


![](/images/k15.png)
  
# [Project 5 : Covid 19 Numbers using Tableau](https://public.tableau.com/profile/samyak5029#!/vizhome/Covid-19_15983430784780/Dashboard1)


![](/images/Dashboard1.png)


# [Project 6 : Neural Network Reduction based on Distinctiveness](https://github.com/u6734495-Samyak/Neural-Network-Pruning)

In this age of deep learning , neural nets with large number neurons and parameters are very common . But , a rule of thumb for obtaining good generalisation is to make sure that we build the smallest system that fits the data. It is essential to prune the network for making it more efficient. In this paper we discuss about one such pruning technique that we learned from a previous paper that is based on the angles between the unit vectors of the hidden layer which are similar or complementary towards the output. Initially we build a simple three layer network to classify different emotions of faces and then compare the results after applying the technique and see how it affects our neural network.


![](/images/AccuracyGraph1.png)


# [Project 7 : Transfer Learning and Network Redution](https://github.com/u6734495-Samyak/Transfer-Learning-with-Network-Redcution-Technique)

The goal of this study was to experiment with the network reduction technique based on distinctiveness. We implemented the technique on a simple feed-forward neural network that dealt with the summarized version of the images and extended our implementation to deep learning that dealt with actual images . Our findings showed us that using deep learning and transfer learning to detect faces-emotion had a higher performance measure than using the summarized version .In addition to this, we experimented with the number of hidden neurons and our research showed us that overall the pruning technique was useful to an extent in removing undesirable and redundant neurons and increasing the performance of our model with a large number of hidden neurons.But on the other hand when the number of hidden neurons are small the pruning had a negative effect on the performance measure.


![](/images/AccuracyGraph1.png)

![](/images/EffectofPruningwithdifferentHiddenUnits.png)











